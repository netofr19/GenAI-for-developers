{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francisco.procopio\\AppData\\Local\\Temp\\ipykernel_17784\\1427206884.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message('Oi?')\n",
    "memory.chat_memory.add_ai_message('Como vai?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Oi?\\nAI: Como vai?'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message('Oi?')\n",
    "memory.chat_memory.add_ai_message('Como vai?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Oi?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Como vai?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando uma conversa com memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francisco.procopio\\AppData\\Local\\Temp\\ipykernel_17784\\2843873365.py:7: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá! Meu nome é Francisco\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Francisco! É um prazer conhecê-lo. Como posso ajudá-lo hoje?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Olá! Meu nome é Francisco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá! Meu nome é Francisco\n",
      "AI: Olá, Francisco! É um prazer conhecê-lo. Como posso ajudá-lo hoje?\n",
      "Human: Qual é o meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seu nome é Francisco. Posso te ajudar com mais alguma coisa?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Qual é o meu nome?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francisco.procopio\\AppData\\Local\\Temp\\ipykernel_17784\\3312290491.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá! Meu nome é Francisco\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Francisco! É um prazer conhecê-lo. Como posso ajudá-lo hoje?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Olá! Meu nome é Francisco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá! Meu nome é Francisco\n",
      "AI: Olá, Francisco! É um prazer conhecê-lo. Como posso ajudá-lo hoje?\n",
      "Human: Como vai?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Estou bem, obrigado por perguntar! Estou aqui para ajudar com qualquer dúvida ou informação que você possa precisar. Como posso ser útil hoje?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Como vai?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Como vai?\n",
      "AI: Estou bem, obrigado por perguntar! Estou aqui para ajudar com qualquer dúvida ou informação que você possa precisar. Como posso ser útil hoje?\n",
      "Human: Qual é o meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas atualmente não tenho acesso a informações pessoais sobre você, incluindo seu nome. Se houver alguma outra pergunta em que eu possa ajudar, fique à vontade para perguntar.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Qual é o meu nome?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francisco.procopio\\AppData\\Local\\Temp\\ipykernel_17784\\2186460629.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=250)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=250)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Me conte uma história de 500 palavras.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! Esta é uma história que ouvi sobre um jovem rapaz chamado Miguel. Miguel vivia em uma pequena aldeia no campo, onde passava seus dias ajudando seus pais na fazenda. Um dia, enquanto Miguel estava trabalhando no campo, ele encontrou um antigo pergaminho enterrado no chão.\\n\\nCurioso, Miguel abriu o pergaminho e descobriu que era um mapa do tesouro! O mapa indicava um local distante nas montanhas, onde supostamente um tesouro valioso estava escondido. Animado com a descoberta, Miguel decidiu embarcar em uma jornada para encontrar o tesouro perdido.\\n\\nCom pouco mais do que sua determinação e um velho machado, Miguel partiu em direção às montanhas. Ele enfrentou desafios no caminho, como ter que atravessar um rio gelado e escalar uma íngreme encosta. Mas Miguel não desistiu, pois estava determinado a encontrar o tesouro prometido pelo mapa.\\n\\nFinalmente, após dias de viagem, Miguel chegou ao local indicado no mapa. Para sua surpresa, ele encontrou uma caverna escura e misteriosa. Com coragem, Miguel entrou na caverna e começou a explorar seu interior.\\n\\nDentro da caverna, Miguel encontrou uma sala cheia de tesouros brilhantes - ouro, joias e relíquias antigas. Ele mal podia acreditar em sua sorte! Miguel encheu sua mochila com o tesouro e começou a fazer o perigoso caminho de volta para casa.\\n\\nAo retornar à aldeia, Miguel foi recebido com festa e celebração. Seus pais ficaram emocionados com a riqueza que ele havia trazido e a coragem que havia demonstrado. Miguel se tornou um herói na aldeia e sua história foi contada por gerações.\\n\\nE assim, o jovem Miguel descobriu que nem todos os tesouros estão enterrados no chão, às vezes o verdadeiro tesouro está dentro de nós mesmos. E essa foi a história de Miguel e sua incrível jornada em busca do tesouro perdido. Espero que tenha gostado!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Me conte uma história de 500 palavras.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Resuma a história anterior\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! A história anterior trata-se de um jovem herói chamado Alex que partiu em uma jornada para resgatar uma princesa em perigo de um vilão malvado. No caminho, ele enfrentou vários desafios, incluindo monstros, armadilhas e adversários espertos. Com coragem e determinação, Alex finalmente chegou ao castelo do vilão e salvou a princesa, trazendo paz de volta ao reino.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Resuma a história anterior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francisco.procopio\\AppData\\Local\\Temp\\ipykernel_17784\\989837566.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=250)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=250)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Olá! Meu nome é Francisco\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá Francisco! Como posso te ajudar hoje?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Olá! Meu nome é Francisco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Olá! Meu nome é Francisco\n",
      "AI: Olá Francisco! Como posso te ajudar hoje?\n",
      "Human: Me conte uma história de 500 palavras.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! Uma vez, em um reino distante, vivia uma princesa chamada Elara. Ela era conhecida por sua beleza e inteligência, mas também por sua teimosia. Um dia, o reino foi invadido por um exército de trolls liderados por um feiticeiro maligno. Eles tomaram o castelo real e aprisionaram o rei e a rainha. Elara conseguiu escapar e decidiu tomar uma atitude.\\n\\nEla sabia que precisava encontrar a lendária espada de luz, capaz de derrotar o feiticeiro e sua horda de trolls. Elara partiu em uma jornada perigosa através de florestas escuras e montanhas traiçoeiras. Ao longo do caminho, ela encontrou aliados improváveis, como um mago errante e um guerreiro destemido.\\n\\nJuntos, o grupo enfrentou desafios terríveis, como um dragão cuspidor de fogo e um labirinto mágico. Mas Elara não desistia, sua determinação era inabalável. Finalmente, eles chegaram à caverna onde a espada de luz estava escondida. Elara enfrentou uma série de testes e, no final, conseguiu empunhar a poderosa arma.\\n\\nCom a espada de luz em mãos, Elara conduziu seus companheiros de volta ao castelo real. Lá, eles enfrentaram o feiticeiro e seus trolls em uma batalha épica. A espada brilhava intensamente, banindo as trevas e restaurando a paz no reino.\\n\\nApós a vitória, Elara foi aclamada como heroína e rainha. Ela reuniu seu povo e reconstruiu o reino, tornando-o mais próspero e seguro do que nunca. E assim, a princesa teimosa se tornou um símbolo de coragem e esperança para todos.\\n\\nE essa foi a história de como a princesa Elara enfrentou todos os desafios para salvar seu reino e se tornar uma verdadeira líder. Espero que tenha gostado da história, Francisco! Posso te ajudar com mais alguma coisa?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Me conte uma história de 500 palavras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human introduces themselves as Francisco and asks the AI to tell a 500-word story. The AI tells the tale of Princess Elara, who faced challenges to save her kingdom and become a true leader. Elara's journey involved finding the legendary sword of light, facing dangerous obstacles, and ultimately defeating the evil sorcerer and his trolls. The story ends with Elara becoming a heroic queen who restores peace and prosperity to the kingdom. Francisco enjoyed the story and the AI offers further assistance.\n",
      "Human: Qual é o meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seu nome é Francisco. Como posso ajudar você hoje, Francisco?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Qual é o meu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human introduces themselves as Francisco and asks the AI to tell a 500-word story. The AI tells the tale of Princess Elara, who faced challenges to save her kingdom and become a true leader. Elara's journey involved finding the legendary sword of light, facing dangerous obstacles, and ultimately defeating the evil sorcerer and his trolls. The story ends with Elara becoming a heroic queen who restores peace and prosperity to the kingdom. Francisco enjoyed the story and the AI offers further assistance.\n",
      "Human: Qual é o meu nome?\n",
      "AI: Seu nome é Francisco. Como posso ajudar você hoje, Francisco?\n",
      "Human: O que pedi para você fazer inicialmente?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Você me pediu para contar uma história de 500 palavras. Espero que tenha gostado da história da Princesa Elara! Existe algo mais que eu possa fazer por você, Francisco?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"O que pedi para você fazer inicialmente?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
