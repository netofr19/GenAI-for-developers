{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.conversation.base import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\francisco.procopio\\AppData\\Local\\Temp\\ipykernel_23240\\2605409397.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\francisco.procopio\\AppData\\Local\\Temp\\ipykernel_23240\\2605409397.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  chain = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Oi!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Oi! How's it going? What‚Äôs on your mind today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(model='gpt-4o-mini')\n",
    "memory = ConversationBufferMemory()\n",
    "chain = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(input=\"Oi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Essa √© uma conversa amig√°vel entre um humano e uma IA.\n",
    "\n",
    "    Conversa atual:\n",
    "\n",
    "    {history}\n",
    "\n",
    "    Human: {input}\n",
    "    Ai:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Essa √© uma conversa amig√°vel entre um humano e uma IA.\n",
      "\n",
      "    Conversa atual:\n",
      "\n",
      "    \n",
      "\n",
      "    Human: Oi!\n",
      "    Ai:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Oi! Como voc√™ est√° hoje? üòä'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(model='gpt-4o-mini')\n",
    "memory = ConversationBufferMemory()\n",
    "chain = ConversationChain(\n",
    "    prompt=prompt_template,\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(input=\"Oi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Essa √© uma conversa amig√°vel entre um humano e uma IA.\n",
      "\n",
      "    Conversa atual:\n",
      "\n",
      "    Human: Oi!\n",
      "AI: Oi! Como voc√™ est√° hoje? üòä\n",
      "\n",
      "    Human: Tudo bem! e voc√™?\n",
      "    Ai:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Estou bem, obrigado! Pronto para conversar e ajudar no que voc√™ precisar. O que voc√™ gostaria de fazer hoje? üòä'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"Tudo bem! e voc√™?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains.llm import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Qual o melhor nome para uma empresa que desenvolve o produto: {produto}\n",
    "    Retorne apenas um nome.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "produto = 'copos de vidro inquebr√°veis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'produto': 'copos de vidro inquebr√°veis', 'text': 'VitraGuard'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(produto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_nome = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Qual o melhor nome para uma empresa que desenvolve o produto: {produto}\n",
    "    Retorne apenas um nome.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_nome = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_nome\n",
    ")\n",
    "\n",
    "prompt_descricao = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Dado a empresa com o seguinte nome: {nome_empresa}.\n",
    "    D√™ uma descri√ß√£o de at√© 50 palavras das atividades dessa empresa.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_descricao = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_descricao\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_final = SimpleSequentialChain(\n",
    "    chains=[chain_nome, chain_descricao],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mVitraflex.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mA Vitraflex √© uma empresa especializada na fabrica√ß√£o e distribui√ß√£o de produtos de vidro flex√≠vel, como embalagens, frascos e tarros. Com foco em inova√ß√£o e qualidade, atende setores como cosm√©ticos, alimentos e farmac√™uticos, oferecendo solu√ß√µes personalizadas que garantem durabilidade e sustentabilidade em suas pr√°ticas.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Copos de vidro inquebr√°veis',\n",
       " 'output': 'A Vitraflex √© uma empresa especializada na fabrica√ß√£o e distribui√ß√£o de produtos de vidro flex√≠vel, como embalagens, frascos e tarros. Com foco em inova√ß√£o e qualidade, atende setores como cosm√©ticos, alimentos e farmac√™uticos, oferecendo solu√ß√µes personalizadas que garantem durabilidade e sustentabilidade em suas pr√°ticas.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produto = 'Copos de vidro inquebr√°veis'\n",
    "\n",
    "chain_final.invoke(produto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chat = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_nome = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Qual o melhor nome para uma empresa que desenvolve o produto: {produto}\n",
    "    Retorne apenas um nome.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_nome = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_nome,\n",
    "    output_key=\"nome_empresa\"\n",
    ")\n",
    "\n",
    "prompt_descricao = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Dado a empresa com o seguinte nome: {nome_empresa} e que produz o seguinte produto: {produto}.\n",
    "    D√™ uma descri√ß√£o de at√© 50 palavras das atividades dessa empresa.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_descricao = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_descricao,\n",
    "    output_key='descricao_empresa'\n",
    ")\n",
    "\n",
    "prompt_traducao = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Crie um nome em ingl√™s para a empresa de nome: {nome_empresa} que possui a seguinte descri√ß√£o: {descricao_empresa}.\n",
    "    Retorne objetivamente apenas um nome para a empresa.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_traducao = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt_traducao,\n",
    "    output_key='nome_ingles'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_final = SequentialChain(\n",
    "    chains=[chain_nome, chain_descricao, chain_traducao],\n",
    "    input_variables=['produto'],\n",
    "    output_variables=['nome_empresa', 'descricao_empresa', 'nome_ingles'],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "produto = 'Copos de vidro inquebr√°veis'\n",
    "\n",
    "resposta = chain_final.invoke(produto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'produto': 'Copos de vidro inquebr√°veis',\n",
       " 'nome_empresa': 'Vitrus.',\n",
       " 'descricao_empresa': 'A Vitrus √© especializada na produ√ß√£o de copos de vidro inquebr√°veis, combinando design moderno e tecnologia avan√ßada para oferecer produtos resistentes e sustent√°veis. Focada em qualidade e inova√ß√£o, a empresa atende tanto o mercado dom√©stico quanto o corporativo, promovendo solu√ß√µes pr√°ticas e elegantes para o cotidiano.',\n",
       " 'nome_ingles': 'GlassGuard Innovations'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Copos de vidro inquebr√°veis'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta['produto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vitrus.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta['nome_empresa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Vitrus √© especializada na produ√ß√£o de copos de vidro inquebr√°veis, combinando design moderno e tecnologia avan√ßada para oferecer produtos resistentes e sustent√°veis. Focada em qualidade e inova√ß√£o, a empresa atende tanto o mercado dom√©stico quanto o corporativo, promovendo solu√ß√µes pr√°ticas e elegantes para o cotidiano.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta['descricao_empresa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GlassGuard Innovations'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta['nome_ingles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
